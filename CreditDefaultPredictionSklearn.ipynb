{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Credit Risk Analysis using Scikit-learn </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default risk is the chance that companies or individuals will be unable to make the required payments on their debt obligations. In other words, credit default risk is the probability that if you lend money, there is a chance that they wonâ€™t be able to give the money back on time.\n",
    "\n",
    "In this example we will train a Logistic Regression model on customers' credit history dataset using scikit-learn.\n",
    "\n",
    "This notebook is a modification to the original notebook from here https://github.com/ibmsoe/snap-ml/blob/master/notebooks/credit-default-prediction-example.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download input dataset of customers' information\n",
    "\n",
    "The datasets contains 1,000,000 transactions with 19 variables in the dataset.\n",
    "\n",
    "You can comment out downloading code below if running the same wget command more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "!wget -O credit_customer_history.csv -nc https://ibm.box.com/shared/static/tr7cz4drh7bwa8kbyw0erjfjh7fort0y.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uname -om"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, normalize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from scipy.stats import chi2_contingency,ttest_ind\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Visualization\n",
    "\n",
    "\n",
    "Let's take a quick look at the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cust_pd_full = pd.read_csv('credit_customer_history.csv')\n",
    "\n",
    "rows=1000000\n",
    "cust_pd = cust_pd_full.head(rows)\n",
    "print(\"There are \" + str(len(cust_pd_full)) + \" observations in the customer history dataset.\")\n",
    "print(\"There are \" + str(len(cust_pd_full.columns)) + \" variables in the dataset.\")\n",
    "\n",
    "cust_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# distribution of output variable default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cust_pd.IS_DEFAULT.value_counts().plot(kind='pie',colormap='winter',autopct='%1.0f%%').legend(bbox_to_anchor=(1.2, 0.6))\n",
    "cust_pd.IS_DEFAULT.value_counts().plot(kind='pie',autopct='%1.0f%%').legend(bbox_to_anchor=(1.2, 0.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Default by Credit Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_pd.TRANSACTION_CATEGORY.value_counts().plot(kind='pie',autopct='%1.0f%%').legend(bbox_to_anchor=(1.2, 0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Top 3 credit programs with most Merchants FURNITURE(43%), ELECTRONICS(32%) and EDUCATION(19%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "COUNT",
      "chartsize": "100",
      "handlerId": "pieChart",
      "keyFields": "IS_DEFAULT",
      "rowCount": "1000"
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "defaults_by_credit_program = cust_pd.groupby(['TRANSACTION_CATEGORY','IS_DEFAULT']).size()\n",
    "percentages = defaults_by_credit_program.groupby(level=0).apply(lambda x:100 * x / float(x.sum()))\n",
    "percentages.unstack().plot(kind='bar',stacked=True,color=['blue','red'],grid=False).legend(bbox_to_anchor=(1.2, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Default by IS_STATE_BORDER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cust_pd.IS_STATE_BORDER.value_counts().plot(kind='pie',autopct='%1.0f%%').legend(bbox_to_anchor=(1.2, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults_by_xborder = cust_pd.groupby(['IS_STATE_BORDER','IS_DEFAULT']).size()\n",
    "percentages = defaults_by_xborder.groupby(level=0).apply(lambda x:100 * x / float(x.sum()))\n",
    "percentages.unstack().plot(kind='bar',stacked=True,  color=['blue','red'], grid=False).legend(bbox_to_anchor=(1.2, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAS_CO_APPLICANT vs. IS_DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "defaults_by_co_applicant = cust_pd.groupby(['HAS_CO_APPLICANT','IS_DEFAULT']).size()\n",
    "percentages = defaults_by_co_applicant.groupby(level=0).apply(lambda x:100 * x / float(x.sum()))\n",
    "percentages.unstack().plot(kind='bar',stacked=True,  color=['blue','red'], grid=False).legend(bbox_to_anchor=(1.2, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREDIT_HISTORY vs. IS_DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_pd.CREDIT_HISTORY.value_counts().plot(kind='bar', title='CREDIT_HISTORY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "defaults_by_history = cust_pd.groupby(['CREDIT_HISTORY','IS_DEFAULT']).size()\n",
    "percentages = defaults_by_history.groupby(level=0).apply(lambda x:100 * x / float(x.sum()))\n",
    "percentages.unstack().plot(kind='bar',stacked=True,color=['blue','red'],grid=False).legend(bbox_to_anchor=(1.2, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cust_pd = cust_pd.sort_values(['IS_DEFAULT'],ascending=[False])\n",
    "#cust_pd = shuffle(cust_pd)\n",
    "cust_pd = cust_pd_full\n",
    "cust_pd.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataframe into Features and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_pd_Y = cust_pd[['IS_DEFAULT']]\n",
    "cust_pd_X = cust_pd.drop(['IS_DEFAULT'],axis=1)\n",
    "\n",
    "print('cust_pd_X.shape=', cust_pd_X.shape, 'cust_pd_Y.shape=', cust_pd_Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_pd_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "cust_pd_Y['IS_DEFAULT'] = le.fit_transform(cust_pd_Y['IS_DEFAULT'])\n",
    "cust_pd_Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMI_TENURE, NUMBER_CREDITS, TRANSACTION_AMOUNT, CREDIT_HISTORY_ALL CREDITS PAID BACK, CREDIT_HISTORY_CRITICAL ACCOUNT, CREDIT_HISTORY_DELAY IN PAST, CREDIT_HISTORY_EXISTING CREDITS PAID BACK, CREDIT_HISTORY_NONE TAKEN etc are some of the features which are being used here for the training and inferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('features df shape = ', cust_pd_X.shape)\n",
    "cust_pd_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding for categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalColumns = ['CREDIT_HISTORY', 'TRANSACTION_CATEGORY', 'ACCOUNT_TYPE', 'ACCOUNT_AGE',\n",
    "                      'STATE', 'IS_URBAN', 'IS_STATE_BORDER', 'HAS_CO_APPLICANT', 'HAS_GUARANTOR',\n",
    "                      'OWN_REAL_ESTATE', 'OTHER_INSTALMENT_PLAN',\n",
    "                      'OWN_RESIDENCE', 'RFM_SCORE', 'OWN_CAR', 'SHIP_INTERNATIONAL']\n",
    "cust_pd_X = pd.get_dummies(cust_pd_X, columns=categoricalColumns)\n",
    "\n",
    "cust_pd_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "features = min_max_scaler.fit_transform(cust_pd_X)\n",
    "features = normalize(features, axis=1, norm='l1')\n",
    "\n",
    "cust_pd_X = pd.DataFrame(features,columns=cust_pd_X.columns)\n",
    "cust_pd_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label    = cust_pd_Y.values\n",
    "features  = cust_pd_X.values\n",
    "\n",
    "label = np.reshape(label,(-1,1))\n",
    "X_train,X_test,y_train,y_test = \\\n",
    "       train_test_split(features, label, test_size=0.3, random_state=42, stratify=label)\n",
    "print('X_train.shape=', X_train.shape, 'Y_train.shape=', y_train.shape)\n",
    "print('X_test.shape=', X_test.shape, 'Y_test.shape=', y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "sklearn_lr = LogisticRegression(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "t0 = time.time()\n",
    "sklearn_lr.fit(X_train, y_train)\n",
    "print(\"[sklearn] Training time (s):  {0:.5f}\".format(time.time()-t0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate log-loss on test set\n",
    "# proba_test = sklearn_lr.predict_proba(X_test)\n",
    "# from sklearn.metrics import log_loss\n",
    "# logloss_sklearn = log_loss(y_test, proba_test)\n",
    "# print(\"[sklearn] Logarithmic loss:   {0:.4f}\".format(logloss_sklearn))\n",
    "sklearn_prediction = sklearn_lr.predict(X_test)\n",
    "print('sklearn ml accuracy score = ', accuracy_score(y_test, sklearn_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&copy; Copyright IBM Corporation 2018, 2020"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
